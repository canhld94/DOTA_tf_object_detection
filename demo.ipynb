{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Intro\n",
    "This notebook provide function and script to convert DOTA annotation to tensorflow object detection format. If you want to explore the dataset, please use there demo notebook.\n",
    "\n",
    "Note: each section is an invidual script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split images \n",
    "Split images to smaller images, default size is 1024x1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "padding: True\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from DOTA_devkit.DOTA import DOTA\n",
    "from DOTA_devkit import dota_utils as util\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "cur_dir = !pwd\n",
    "hi_res_dir = 'DOTA_devkit/example'\n",
    "split_dir = 'DOTA_devkit/examplesplit'\n",
    "# hi_res_dir = 'dataset/high_res_train/'\n",
    "# split_dir = 'dataset/train/'\n",
    "# hi_res_dir = 'dataset/high_res_val/'\n",
    "# split_dir = 'dataset/val/'\n",
    "\n",
    "hi_res_dir = os.path.join(cur_dir[0],hi_res_dir)\n",
    "split_dir = os.path.join(cur_dir[0],split_dir)\n",
    "\n",
    "if not os.path.exists(split_dir):\n",
    "    !mkdir $split_dir\n",
    "\n",
    "split_im_dir = os.path.join(split_dir,'images')\n",
    "if not os.path.exists(split_im_dir):\n",
    "    !mkdir $split_im_dir\n",
    "\n",
    "split_txt_dir = os.path.join(split_dir,'labelTxt')\n",
    "if not os.path.exists(split_txt_dir):\n",
    "    !mkdir $split_txt_dir\n",
    "\n",
    "split = splitbase(hi_res_dir,split_dir,choosebestpoint=True)\n",
    "split.splitdata(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/val set\n",
    "DOTA provide val set, but it's relatively big for using in trainning evaluation. Instead, we randomly choose 300 images from full set to use as val set (or you can choose from training dataset as well). The below script will consume the full data directory, randomly choose 300 images and copy these images (and annotations as well) to a new dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "300\n"
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "cur_dir = !pwd\n",
    "num_vals = 300\n",
    "full_data_dir = 'dataset/val_full'\n",
    "full_im_dir = os.path.join(full_data_dir,'images')\n",
    "full_txt_dir = os.path.join(full_data_dir,'labelTxt')\n",
    "\n",
    "if not os.path.exists(full_im_dir):\n",
    "    sys.exit(\"images folder not found in \" + full_data_dir)\n",
    "if not os.path.exists(full_txt_dir):\n",
    "    sys.exit(\"labelTxt folder not found in \" + full_data_dir)\n",
    "\n",
    "val_data_dir = 'dataset/val'\n",
    "if not os.path.exists(val_data_dir):\n",
    "    !mkdir $val_data_dir\n",
    "val_im_dir = os.path.join(val_data_dir,'images')\n",
    "if not os.path.exists(val_im_dir):\n",
    "    !mkdir $val_im_dir\n",
    "val_txt_dir = os.path.join(val_data_dir,'labelTxt')\n",
    "if not os.path.exists(val_txt_dir):\n",
    "    !mkdir $val_txt_dir\n",
    "\n",
    "img_list = []\n",
    "for x in os.listdir(full_im_dir):\n",
    "    if not os.path.isdir(x):\n",
    "        img_list.append(x)\n",
    "random.seed(300)\n",
    "selected_list = random.choices(img_list,k=num_vals)\n",
    "print(len(selected_list))\n",
    "for img in selected_list:\n",
    "    # print(img)\n",
    "    shutil.copy(src=os.path.join(full_im_dir,img),dst=val_im_dir)\n",
    "    txt = img.replace('.png','.txt')\n",
    "    shutil.copy(src=os.path.join(full_txt_dir,txt),dst=val_txt_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensorflow object detection records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import PIL.Image\n",
    "from DOTA_devkit import dota_utils as util\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "def create_tf_example(data,\n",
    "                      imagepath,\n",
    "                      label_map_dict,\n",
    "                      filename,\n",
    "                      ignore_difficult_instances=True\n",
    "                      ):\n",
    "  # TODO(user): Populate the following variables from your example.\n",
    "  full_path = os.path.join(imagepath, filename + '.png')\n",
    "  with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_png = fid.read()\n",
    "  encoded_png_io = io.BytesIO(encoded_png)\n",
    "  image = PIL.Image.open(encoded_png_io)\n",
    "  if image.format != 'PNG':\n",
    "    raise ValueError('Image format not PNG')\n",
    "\n",
    "  width = 1024\n",
    "  height = 1024\n",
    "  image_format = None # b'jpeg' or b'png'\n",
    "\n",
    "  xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "  xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "  ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "  classes = [] # List of integer class id of bounding box (1 per box)\n",
    "  difficult_obj = []\n",
    "  for obj in data:\n",
    "    difficult = bool(int(obj['difficult']))\n",
    "    if ignore_difficult_instances and difficult:\n",
    "      continue\n",
    "    xmin = max(obj['bndbox'][0], 0)\n",
    "    ymin = max(obj['bndbox'][1], 0)\n",
    "    xmax = min(obj['bndbox'][2], width - 1)\n",
    "    ymax = min(obj['bndbox'][3], height - 1)\n",
    "\n",
    "    difficult_obj.append(int(difficult))\n",
    "\n",
    "    xmins.append(float(xmin) / width)\n",
    "    ymins.append(float(ymin) / height)\n",
    "    xmaxs.append(float(xmax) / width)\n",
    "    ymaxs.append(float(ymax) / height)\n",
    "\n",
    "    classes_text.append(obj['name'].encode('utf8'))\n",
    "    if (obj['name'] in label_map_dict):\n",
    "        classes.append(label_map_dict[obj['name']])\n",
    "\n",
    "    else:\n",
    "        print('>>>>>>>>>>>>>')\n",
    "        continue\n",
    "\n",
    "\n",
    "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_png),\n",
    "      'image/format': dataset_util.bytes_feature('png'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "  has_object = True\n",
    "  if len(xmins) == 0:\n",
    "    has_object = False\n",
    "  #print 'tf_example: ', tf_example\n",
    "  return tf_example, has_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There is 207 valid images in total 297 images!\nstart-------\nThere is 29 file without valid objects!\nDone, record is written to /home/canhld/workplace/SomeThing/trainning/dota/dataset/val/tf_records\n"
    }
   ],
   "source": [
    "import os\n",
    "cur_dir = !pwd\n",
    "data_dir = 'dataset/val/'\n",
    "label_map = 'annotations/dota_label_map.pbtxt'\n",
    "output_name = 'dota_val.record'\n",
    "index_file = 'val.txt'\n",
    "data_dir = os.path.join(cur_dir[0],data_dir)\n",
    "label_map = os.path.join(cur_dir[0],label_map)\n",
    "\n",
    "# create index file, we should also avoid any images with no box at all\n",
    "# 1/3 images have no box, which painfully increase the trainning time\n",
    "data_txt_dir = os.path.join(data_dir,'labelTxt')\n",
    "img_list = []\n",
    "total = 0\n",
    "for x in os.listdir(data_txt_dir):\n",
    "    f = os.path.join(data_txt_dir,x)\n",
    "    if not os.path.isdir(f):\n",
    "        total += 1\n",
    "        if os.stat(f).st_size != 0:\n",
    "            img_list.append(f.replace(\"labelTxt\",\"images\").replace(\".txt\",\".png\"))\n",
    "print(\"There is \" + str(len(img_list)) + \" valid images in total \" + str(total) + \" images!\")\n",
    "with open(os.path.join(data_dir,index_file),'w') as f:\n",
    "    for item in img_list:\n",
    "        f.write(\"%s\\n\" %item)\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, index_file)):\n",
    "    # print os.path.join(data_dir, indexfile)\n",
    "    raise ValueError('{} not in the path: {}'.format(index_file, data_dir))\n",
    "\n",
    "output_path = os.path.join(data_dir, 'tf_records')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(os.path.join(output_path, output_name))\n",
    "print ('start-------')\n",
    "# TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "imagepath = os.path.join(data_dir, 'images')\n",
    "f = open(os.path.join(data_dir, index_file), 'r')\n",
    "lines = f.readlines()\n",
    "txtlist = [x.strip().replace(r'images', r'labelTxt').replace('.png', '.txt') for x in lines]\n",
    "# txtlist = util.GetFileFromThisRootDir(os.path.join(data_dir, 'wordlabel'))\n",
    "no_object = 0\n",
    "for fullname in txtlist:\n",
    "    data = util.parse_dota_rec(fullname)\n",
    "    # print 'len(data):', len(data)\n",
    "    # print('data: ' + str(data))\n",
    "    # assert len(data) >= 0, \"there exists empty data: \" + fullname\n",
    "    basename = os.path.basename(os.path.splitext(fullname)[0])\n",
    "    label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "    # print 'label_map_dict', label_map_dict\n",
    "    tf_example, has_object = create_tf_example(data,\n",
    "                                    imagepath,\n",
    "                                    label_map_dict,\n",
    "                                    basename)\n",
    "    if has_object:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    else: \n",
    "        no_object += 1\n",
    "writer.close()\n",
    "print(\"There is \" + str(no_object) + \" file without valid objects!\")\n",
    "print(\"Done, record is written to \" + output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}