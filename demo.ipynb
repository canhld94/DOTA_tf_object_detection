{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Intro\n",
    "This notebook provide function and script to convert DOTA annotation to tensorflow object detection format. If you want to explore the dataset, please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from DOTA_devkit.DOTA import DOTA\n",
    "from DOTA_devkit import dota_utils as util\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 10.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split images\n",
    "Split images and annotation to smaller images. The default size is 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DOTA_devkit.ImgSplit_multi_process import splitbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "padding: True\n"
    }
   ],
   "source": [
    "cur_dir = !pwd\n",
    "\n",
    "hi_res_dir = 'DOTA_devkit/example'\n",
    "split_dir = 'DOTA_devkit/examplesplit'\n",
    "# hi_res_dir = 'dataset/high_res_train/'\n",
    "# split_dir = 'dataset/train/'\n",
    "# hi_res_dir = 'dataset/high_res_val/'\n",
    "# split_dir = 'dataset/val/'\n",
    "\n",
    "hi_res_dir = os.path.join(cur_dir[0],hi_res_dir)\n",
    "split_dir = os.path.join(cur_dir[0],split_dir)\n",
    "\n",
    "if not os.path.exists(split_dir):\n",
    "    !mkdir $split_dir\n",
    "\n",
    "split_im_dir = os.path.join(split_dir,'images')\n",
    "if not os.path.exists(split_im_dir):\n",
    "    !mkdir $split_im_dir\n",
    "\n",
    "split_txt_dir = os.path.join(split_dir,'labelTxt')\n",
    "if not os.path.exists(split_txt_dir):\n",
    "    !mkdir $split_txt_dir\n",
    "\n",
    "split = splitbase(hi_res_dir,split_dir,choosebestpoint=True)\n",
    "split.splitdata(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove junk images from training set\n",
    "There are many image in the training set which have no object at all, which slowdown the training process\n",
    "Or as an alternative, set suffle to true while training the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/val set\n",
    "DOTA provide val set, but it's relatively big for using in trainning evaluation. Instead, we randomly choose 300 images from full set to use as val set (or you can choose from training dataset as well). The below script will consume the full data directory, randomly choose 300 images and copy these images (and annotations as well) to a new dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "300\n"
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "cur_dir = !pwd\n",
    "num_vals = 300\n",
    "full_data_dir = 'dataset/val_full'\n",
    "full_im_dir = os.path.join(full_data_dir,'images')\n",
    "full_txt_dir = os.path.join(full_data_dir,'labelTxt')\n",
    "\n",
    "if not os.path.exists(full_im_dir):\n",
    "    sys.exit(\"images folder not found in \" + full_data_dir)\n",
    "if not os.path.exists(full_txt_dir):\n",
    "    sys.exit(\"labelTxt folder not found in \" + full_data_dir)\n",
    "\n",
    "val_data_dir = 'dataset/val'\n",
    "if not os.path.exists(val_data_dir):\n",
    "    !mkdir $val_data_dir\n",
    "val_im_dir = os.path.join(val_data_dir,'images')\n",
    "if not os.path.exists(val_im_dir):\n",
    "    !mkdir $val_im_dir\n",
    "val_txt_dir = os.path.join(val_data_dir,'labelTxt')\n",
    "if not os.path.exists(val_txt_dir):\n",
    "    !mkdir $val_txt_dir\n",
    "\n",
    "img_list = []\n",
    "for x in os.listdir(full_im_dir):\n",
    "    if not os.path.isdir(x):\n",
    "        img_list.append(x)\n",
    "random.seed(300)\n",
    "selected_list = random.choices(img_list,k=num_vals)\n",
    "print(len(selected_list))\n",
    "for img in selected_list:\n",
    "    # print(img)\n",
    "    shutil.copy(src=os.path.join(full_im_dir,img),dst=val_im_dir)\n",
    "    txt = img.replace('.png','.txt')\n",
    "    shutil.copy(src=os.path.join(full_txt_dir,txt),dst=val_txt_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensorflow object detection records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import io\n",
    "import PIL.Image\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(data,\n",
    "                      imagepath,\n",
    "                      label_map_dict,\n",
    "                      filename,\n",
    "                      ignore_difficult_instances=True\n",
    "                      ):\n",
    "  # TODO(user): Populate the following variables from your example.\n",
    "  full_path = os.path.join(imagepath, filename + '.png')\n",
    "  with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_png = fid.read()\n",
    "  encoded_png_io = io.BytesIO(encoded_png)\n",
    "  image = PIL.Image.open(encoded_png_io)\n",
    "  if image.format != 'PNG':\n",
    "    raise ValueError('Image format not PNG')\n",
    "\n",
    "  width = 1024\n",
    "  height = 1024\n",
    "  image_format = None # b'jpeg' or b'png'\n",
    "\n",
    "  xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "  xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "  ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "  classes = [] # List of integer class id of bounding box (1 per box)\n",
    "  difficult_obj = []\n",
    "  for obj in data:\n",
    "    difficult = bool(int(obj['difficult']))\n",
    "    if ignore_difficult_instances and difficult:\n",
    "      continue\n",
    "    xmin = max(obj['bndbox'][0], 0)\n",
    "    ymin = max(obj['bndbox'][1], 0)\n",
    "    xmax = min(obj['bndbox'][2], width - 1)\n",
    "    ymax = min(obj['bndbox'][3], height - 1)\n",
    "\n",
    "    difficult_obj.append(int(difficult))\n",
    "\n",
    "    xmins.append(float(xmin) / width)\n",
    "    ymins.append(float(ymin) / height)\n",
    "    xmaxs.append(float(xmax) / width)\n",
    "    ymaxs.append(float(ymax) / height)\n",
    "\n",
    "    classes_text.append(obj['name'].encode('utf8'))\n",
    "    if (obj['name'] in label_map_dict):\n",
    "        classes.append(label_map_dict[obj['name']])\n",
    "\n",
    "    else:\n",
    "        print('>>>>>>>>>>>>>')\n",
    "        continue\n",
    "\n",
    "\n",
    "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_png),\n",
    "      'image/format': dataset_util.bytes_feature('png'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "  #print 'tf_example: ', tf_example\n",
    "  return tf_example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start-------\nDone, record is written to \n"
    }
   ],
   "source": [
    "cur_dir = !pwd\n",
    "\n",
    "data_dir = 'dataset/val/'\n",
    "label_map = 'annotations/dota_label_map.pbtxt'\n",
    "output_name = 'dota_val.record'\n",
    "index_file = 'val.txt'\n",
    "data_dir = os.path.join(cur_dir[0],data_dir)\n",
    "label_map = os.path.join(cur_dir[0],label_map)\n",
    "\n",
    "# create index file\n",
    "data_im_dir = os.path.join(data_dir,'images')\n",
    "\n",
    "!cd $data_dir && find $data_im_dir -type f -name *.png > $index_file\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, index_file)):\n",
    "    # print os.path.join(data_dir, indexfile)\n",
    "    raise ValueError('{} not in the path: {}'.format(index_file, data_dir))\n",
    "\n",
    "output_path = os.path.join(data_dir, 'tf_records')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(os.path.join(output_path, output_name))\n",
    "print ('start-------')\n",
    "# TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "imagepath = os.path.join(data_dir, 'images')\n",
    "f = open(os.path.join(data_dir, index_file), 'r')\n",
    "lines = f.readlines()\n",
    "txtlist = [x.strip().replace(r'images', r'labelTxt').replace('.png', '.txt') for x in lines]\n",
    "# txtlist = util.GetFileFromThisRootDir(os.path.join(data_dir, 'wordlabel'))\n",
    "for fullname in txtlist:\n",
    "    data = util.parse_dota_rec(fullname)\n",
    "    # print 'len(data):', len(data)\n",
    "    # print 'data:', data\n",
    "    # assert len(data) >= 0, \"there exists empty data: \" + fullname\n",
    "    basename = os.path.basename(os.path.splitext(fullname)[0])\n",
    "    label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "    # print 'label_map_dict', label_map_dict\n",
    "    tf_example = create_tf_example(data,\n",
    "                                    imagepath,\n",
    "                                    label_map_dict,\n",
    "                                    basename)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()\n",
    "print(\"Done, record is written to \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}